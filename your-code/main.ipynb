{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Avila Bible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will explore the [**Avila Bible dataset**](https://archive.ics.uci.edu/ml/datasets/Avila) which has been extracted from 800 images of the 'Avila Bible', an XII century giant Latin copy of the Bible. The prediction task consists in associating each pattern to a copyist. You will use supervised learning algorithms to figure out what feature patterns each copyist are likely to have and use our model to predict those copyist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before your start:\n",
    "    - Read the README.md file,\n",
    "    - Comment as much as you can and use the APIla-bible in the README.md,\n",
    "    - Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![machine-learning](https://miro.medium.com/proxy/1*halC1X4ydv_3yHYxKqvrwg.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Avila data set has been extracted from 800 images of the the **Avila Bible**, a giant Latin copy of the whole Bible produced during the XII century between Italy and Spain. The palaeographic analysis of the  manuscript has  individuated the presence of 12 copyists. The pages written by each copyist are not equally numerous. \n",
    "Each pattern contains 10 features and corresponds to a group of 4 consecutive rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What am I expected to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, your prediction task consists in associating each pattern to one of the 8 monks we will be evaluating (labeled as:  Marcus, Clarius, Philippus, Coronavirucus, Mongucus, Paithonius, Ubuntius, Esequlius). For that aim, you should: \n",
    "- Train a minimum of 4 different models\n",
    "- Perform a minimum of 4 Feature Extraction and Engineering techniques\n",
    "- Must contain a summary of the machine learning tools and algorithms\n",
    "- and the results or the score obtained with each of them\n",
    "\n",
    "You won't get much more instructions from now on. Remember to comment your code as much as you can. Keep the requirements in mind and have fun! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just one last piece of advice, take a moment to explore the data, remember this dataset contains two files: **train** and **test**. You will find both files in `data` folder. The **test** files contains the data you will predict for, therefore it does not include the labels.\n",
    "Use the **train** dataset as you wish, but don't forget to split it into **train** and **test** again so you can evaluate your models. Just be sure to train it again with the whole data before predicting.\n",
    "We have also included a **sample submission** which is of the exact shape and format you must use when evaluating your predictions against the groundtruth through the `APIla-bible`. It won't work unless it is the exact same shape. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('../data/training_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.241386</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>-0.127126</td>\n",
       "      <td>0.380626</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.314889</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.316412</td>\n",
       "      <td>0.188810</td>\n",
       "      <td>0.134922</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.303106</td>\n",
       "      <td>0.352558</td>\n",
       "      <td>0.082701</td>\n",
       "      <td>0.703981</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.391033</td>\n",
       "      <td>0.408929</td>\n",
       "      <td>1.045014</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>-0.448209</td>\n",
       "      <td>Clarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.281897</td>\n",
       "      <td>0.175168</td>\n",
       "      <td>-0.152490</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.889332</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>-0.024328</td>\n",
       "      <td>0.905984</td>\n",
       "      <td>-0.877830</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.326430</td>\n",
       "      <td>-0.652394</td>\n",
       "      <td>0.384996</td>\n",
       "      <td>-1.694222</td>\n",
       "      <td>-0.185173</td>\n",
       "      <td>-1.138481</td>\n",
       "      <td>-0.232828</td>\n",
       "      <td>-1.747116</td>\n",
       "      <td>-1.183175</td>\n",
       "      <td>-0.807380</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.437525</td>\n",
       "      <td>-0.471816</td>\n",
       "      <td>0.463236</td>\n",
       "      <td>-0.545248</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.972381</td>\n",
       "      <td>0.824183</td>\n",
       "      <td>-3.108388</td>\n",
       "      <td>-2.991700</td>\n",
       "      <td>-1.141030</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.241386  0.109171 -0.127126  0.380626  0.172340  0.314889  0.484429   \n",
       "1  0.303106  0.352558  0.082701  0.703981  0.261718 -0.391033  0.408929   \n",
       "2 -0.116585  0.281897  0.175168 -0.152490  0.261718 -0.889332  0.371178   \n",
       "3 -0.326430 -0.652394  0.384996 -1.694222 -0.185173 -1.138481 -0.232828   \n",
       "4 -0.437525 -0.471816  0.463236 -0.545248  0.261718 -0.972381  0.824183   \n",
       "\n",
       "          7         8         9         10  \n",
       "0  0.316412  0.188810  0.134922     Marcus  \n",
       "1  1.045014  0.282354 -0.448209    Clarius  \n",
       "2 -0.024328  0.905984 -0.877830  Philippus  \n",
       "3 -1.747116 -1.183175 -0.807380  Philippus  \n",
       "4 -3.108388 -2.991700 -1.141030  Philippus  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('../data/test_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.017834</td>\n",
       "      <td>0.132725</td>\n",
       "      <td>0.125378</td>\n",
       "      <td>1.357345</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.190314</td>\n",
       "      <td>0.182426</td>\n",
       "      <td>0.445253</td>\n",
       "      <td>-0.715453</td>\n",
       "      <td>0.189796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.202992</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-0.527256</td>\n",
       "      <td>0.082961</td>\n",
       "      <td>0.771662</td>\n",
       "      <td>0.144676</td>\n",
       "      <td>0.098572</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>0.745333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.019049</td>\n",
       "      <td>0.211237</td>\n",
       "      <td>-0.155578</td>\n",
       "      <td>-0.311855</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.107265</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.339303</td>\n",
       "      <td>-0.310094</td>\n",
       "      <td>-0.049630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.451232</td>\n",
       "      <td>-0.267686</td>\n",
       "      <td>0.335206</td>\n",
       "      <td>-0.831336</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>0.220177</td>\n",
       "      <td>0.988787</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>0.025485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.227680</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>0.413447</td>\n",
       "      <td>0.118917</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.480988</td>\n",
       "      <td>0.522180</td>\n",
       "      <td>0.091562</td>\n",
       "      <td>0.313536</td>\n",
       "      <td>0.256389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.017834  0.132725  0.125378  1.357345  0.261718  0.190314  0.182426   \n",
       "1 -0.202992 -0.000745 -3.210528 -0.527256  0.082961  0.771662  0.144676   \n",
       "2  1.019049  0.211237 -0.155578 -0.311855  0.261718  0.107265  0.484429   \n",
       "3  0.451232 -0.267686  0.335206 -0.831336  0.261718  0.024215  0.220177   \n",
       "4 -0.227680  0.109171  0.413447  0.118917  0.172340  0.480988  0.522180   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.445253 -0.715453  0.189796  \n",
       "1  0.098572  0.251173  0.745333  \n",
       "2  0.339303 -0.310094 -0.049630  \n",
       "3  0.988787  0.032902  0.025485  \n",
       "4  0.091562  0.313536  0.256389  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ubuntius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esequlius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coronavirucus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1\n",
       "0               \n",
       "0      Philippus\n",
       "1       Ubuntius\n",
       "2      Esequlius\n",
       "3  Coronavirucus\n",
       "4      Philippus"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keep calm and code on!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - train your models, make the best prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     float64\n",
       "1     float64\n",
       "2     float64\n",
       "3     float64\n",
       "4     float64\n",
       "5     float64\n",
       "6     float64\n",
       "7     float64\n",
       "8     float64\n",
       "9     float64\n",
       "10     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Clarius       0.60      0.30      0.40       459\n",
      "Coronavirucus       0.99      0.97      0.98       202\n",
      "    Esequlius       1.00      0.04      0.08        94\n",
      "       Marcus       0.64      0.92      0.76      1035\n",
      "     Mongucus       0.90      0.80      0.85       130\n",
      "   Paithonius       0.68      0.30      0.41       121\n",
      "    Philippus       0.62      0.66      0.64       256\n",
      "     Ubuntius       0.66      0.25      0.36       107\n",
      "\n",
      "     accuracy                           0.68      2404\n",
      "    macro avg       0.76      0.53      0.56      2404\n",
      " weighted avg       0.69      0.68      0.64      2404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = train_dataset.drop(['10'],axis=1)\n",
    "\n",
    "y = train_dataset['10']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = svm.SVC()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'GT')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred, normalize=\"true\")\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.xlabel(\"Pred\")\n",
    "plt.ylabel(\"GT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = [\n",
    "    StandardScaler(),\n",
    "    Normalizer(),\n",
    "]\n",
    "\n",
    "tr = make_pipeline(*pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = tr.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marcus</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clarius</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philippus</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philippus</td>\n",
       "      <td>Clarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Philippus</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mongucus</td>\n",
       "      <td>Mongucus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clarius</td>\n",
       "      <td>Clarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Clarius</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Marcus</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ubuntius</td>\n",
       "      <td>Paithonius</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gt  prediction\n",
       "0     Marcus      Marcus\n",
       "1    Clarius      Marcus\n",
       "2  Philippus   Philippus\n",
       "3  Philippus     Clarius\n",
       "4  Philippus      Marcus\n",
       "5   Mongucus    Mongucus\n",
       "6    Clarius     Clarius\n",
       "7    Clarius      Marcus\n",
       "8     Marcus      Marcus\n",
       "9   Ubuntius  Paithonius"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(X)\n",
    "\n",
    "\n",
    "model = LogisticRegression(solver=\"lbfgs\")\n",
    "model.fit(X,y)\n",
    "\n",
    "y_pred = model.predict(X[:10])\n",
    "pd.DataFrame({\n",
    "    \"gt\":y[:10],\n",
    "    \"prediction\":y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Clarius', 'Marcus', 'Marcus', ..., 'Marcus', 'Clarius',\n",
       "       'Philippus'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "models = {\n",
    "    \"logis\": LogisticRegression(C=10,solver=\"lbfgs\"),\n",
    "    \"svm-linear\": CalibratedClassifierCV(LinearSVC(),cv=3),\n",
    "    \"svm-rbf\": CalibratedClassifierCV(SVC(kernel=\"poly\",gamma=\"auto\", max_iter=200),cv=3),\n",
    "    \"randomforest\": RandomForestClassifier(n_estimators=300)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm-linear...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm-rbf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training randomforest...\n",
      "Train complete\n"
     ]
    }
   ],
   "source": [
    "for name,m  in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    m.fit(X_train, y_train)\n",
    "print(\"Train complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model logis\n",
      "\t Accuracy: 0.58\n",
      "\t Precision: 0.58\n",
      "\t Recall: 0.58\n",
      "\t F1Score: 0.58\n",
      "Evaluating model svm-linear\n",
      "\t Accuracy: 0.548\n",
      "\t Precision: 0.548\n",
      "\t Recall: 0.548\n",
      "\t F1Score: 0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model svm-rbf\n",
      "\t Accuracy: 0.533\n",
      "\t Precision: 0.533\n",
      "\t Recall: 0.533\n",
      "\t F1Score: 0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model randomforest\n",
      "\t Accuracy: 0.985\n",
      "\t Precision: 0.985\n",
      "\t Recall: 0.985\n",
      "\t F1Score: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "printMetric = lambda label,value:print(f\"\\t {label}: {round(value,3)}\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Evaluating model {name}\")\n",
    "    printMetric(\"Accuracy\",accuracy_score(y_test, y_pred))\n",
    "    printMetric(\"Precision\",precision_score(y_test, y_pred,pos_label='positive',average='micro'))\n",
    "    printMetric(\"Recall\",recall_score(y_test, y_pred,pos_label='positive',average='micro'))\n",
    "    printMetric(\"F1Score\",f1_score(y_test, y_pred,pos_label='positive',average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL -> logis\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Clarius       0.45      0.13      0.20       459\n",
      "Coronavirucus       0.92      0.88      0.90       202\n",
      "    Esequlius       0.00      0.00      0.00        94\n",
      "       Marcus       0.55      0.93      0.69      1035\n",
      "     Mongucus       0.83      0.75      0.79       130\n",
      "   Paithonius       0.50      0.17      0.26       121\n",
      "    Philippus       0.49      0.29      0.37       256\n",
      "     Ubuntius       0.00      0.00      0.00       107\n",
      "\n",
      "     accuracy                           0.58      2404\n",
      "    macro avg       0.47      0.40      0.40      2404\n",
      " weighted avg       0.52      0.58      0.51      2404\n",
      "\n",
      "MODEL -> svm-linear\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Clarius       0.28      0.05      0.08       459\n",
      "Coronavirucus       0.91      0.89      0.90       202\n",
      "    Esequlius       0.00      0.00      0.00        94\n",
      "       Marcus       0.51      0.97      0.67      1035\n",
      "     Mongucus       0.87      0.69      0.77       130\n",
      "   Paithonius       0.75      0.02      0.05       121\n",
      "    Philippus       0.34      0.09      0.15       256\n",
      "     Ubuntius       0.00      0.00      0.00       107\n",
      "\n",
      "     accuracy                           0.55      2404\n",
      "    macro avg       0.46      0.34      0.33      2404\n",
      " weighted avg       0.47      0.55      0.44      2404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL -> svm-rbf\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Clarius       0.33      0.00      0.00       459\n",
      "Coronavirucus       0.88      0.81      0.84       202\n",
      "    Esequlius       0.00      0.00      0.00        94\n",
      "       Marcus       0.48      0.98      0.65      1035\n",
      "     Mongucus       0.85      0.77      0.81       130\n",
      "   Paithonius       0.00      0.00      0.00       121\n",
      "    Philippus       0.00      0.00      0.00       256\n",
      "     Ubuntius       0.00      0.00      0.00       107\n",
      "\n",
      "     accuracy                           0.53      2404\n",
      "    macro avg       0.32      0.32      0.29      2404\n",
      " weighted avg       0.39      0.53      0.39      2404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL -> randomforest\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Clarius       1.00      0.99      0.99       459\n",
      "Coronavirucus       1.00      0.99      1.00       202\n",
      "    Esequlius       0.99      0.97      0.98        94\n",
      "       Marcus       0.98      1.00      0.99      1035\n",
      "     Mongucus       0.98      0.95      0.97       130\n",
      "   Paithonius       0.99      0.94      0.97       121\n",
      "    Philippus       0.95      0.98      0.97       256\n",
      "     Ubuntius       0.99      0.96      0.98       107\n",
      "\n",
      "     accuracy                           0.98      2404\n",
      "    macro avg       0.99      0.97      0.98      2404\n",
      " weighted avg       0.98      0.98      0.98      2404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"MODEL -> {name}\")\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(logis) acccuracy=0.5844216065092734\n",
      "(svm-linear) acccuracy=0.575017283156992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(svm-rbf) acccuracy=0.5202623714846613\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-eb7baf1ac12f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"({name}) acccuracy={np.mean(scores)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    386\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    228\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    229\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 230\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    231\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    232\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    256\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    256\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    378\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    256\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    256\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         indices = _generate_sample_indices(tree.random_state, n_samples,\n\u001b[0m\u001b[1;32m    154\u001b[0m                                            n_samples_bootstrap)\n\u001b[1;32m    155\u001b[0m         \u001b[0msample_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_generate_sample_indices\u001b[0;34m(random_state, n_samples, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mrandom_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0msample_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msample_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2959\u001b[0m     \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \"\"\"\n\u001b[0;32m-> 2961\u001b[0;31m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[1;32m   2962\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=10)\n",
    "    print(f\"({name}) acccuracy={np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do I do once I have a prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have already trained your model and made a prediction with it, you are ready to check what is the accuracy of it. \n",
    "\n",
    "Save your prediction as a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../predict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to know the truth! Are you good enough to call yourself a pro?\n",
    "\n",
    "Lucky you have the ultimate **APIla-bible** which give you the chance of checking the accuracy of your predictions as many times as you need in order to become the pro you want to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I post my prediction to the APIla-bible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy peasy! You should only fulfil the path to your prediction `.csv` and run the cell below! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ERROR': 406,\n",
       " 'Who you gonna call?': 'Ghostbusters!',\n",
       " 'description': 'Not acceptable. Expected shape of (8012, 1), instead got (12018, 10)'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission = \"../predict.csv\"\n",
    "with open(my_submission) as f:\n",
    "    res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hope-you-enjoy](https://imgs.xkcd.com/comics/machine_learning.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
